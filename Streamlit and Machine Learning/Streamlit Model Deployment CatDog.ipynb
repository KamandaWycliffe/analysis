{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting deployment.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile deployment.py\n",
    "import streamlit as st\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "st.title(\"Cat/Dog Streamlit Classifier\")\n",
    "st.header(\"Please input an image to be classified:\")\n",
    "\n",
    "@st.cache(allow_output_mutation=True)\n",
    "\n",
    "def dog_cat_classifier(img, model):\n",
    "    '''\n",
    "    Teachable machine learning classifier for dog-cat classification:\n",
    "    Parameters\n",
    "    {\n",
    "    img: Image to be classified\n",
    "    model : trained model\n",
    "    \n",
    "    }\n",
    "    '''\n",
    "    # Load the model that was saved earlier\n",
    "    model = keras.models.load_model(model)\n",
    "\n",
    "    '''Define the array of the right shape to feed into the keras model'''\n",
    "    \n",
    "    data = np.ndarray(shape=(1, 200, 200, 3), dtype=np.float32)\n",
    "    image = img\n",
    "    #resizing the image\n",
    "    size = (200, 200)\n",
    "    image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
    "\n",
    "    #convert the image into a numpy array\n",
    "    image_array = np.asarray(image)\n",
    "    # Image processing (normalization)\n",
    "    normalized_image = (image_array.astype(np.float32) / 255)\n",
    "\n",
    "    # Load the image into the array\n",
    "    data[0] = normalized_image\n",
    "\n",
    "    # carryout predictions\n",
    "    prediction_rate = model.predict(data)\n",
    "    prediction = prediction_rate.round()\n",
    "    \n",
    "    return  prediction,prediction_rate\n",
    "\n",
    "#prompt user for an image\n",
    "uploaded_image = st.file_uploader(\"Select an image with Cat or Dog Image...\", type=\"jpg\")\n",
    "\n",
    "if uploaded_image is not None:\n",
    "    image = Image.open(uploaded_image)\n",
    "    st.image(image, caption='Uploaded file', use_column_width=True)\n",
    "    st.write(\"\")\n",
    "    st.write(\"Classifying please wait...\")\n",
    "    label,conf = dog_cat_classifier(image, 'catdog.h5')\n",
    "    if label == 1:\n",
    "        st.write(\"This is a Dog, with:\",conf, \"confidence\")\n",
    "    else:\n",
    "        st.write(\"This is a Cat, with:\",1-conf, \"confidence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 21:29:06.920 INFO    numexpr.utils: NumExpr defaulting to 4 threads.\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.0.104:8501\u001b[0m\n",
      "\u001b[0m\n",
      "2022-08-08 21:29:13.061803: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-08 21:29:13.061843: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-08-08 21:29:50.057477: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/kamanda/anaconda/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-08-08 21:29:50.057570: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-08 21:29:50.057639: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (kamanda): /proc/driver/nvidia/version does not exist\n",
      "1/1 [==============================] - 5s 5s/step\n"
     ]
    }
   ],
   "source": [
    "!streamlit run deployment.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pillow Version: 9.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-08 21:11:39.727336: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-08 21:11:39.727386: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-08-08 21:11:43.419475: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/kamanda/anaconda/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-08-08 21:11:43.419524: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-08 21:11:43.419551: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (kamanda): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-08 21:11:53.415395: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 112320000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 77s 8s/step - loss: 0.3550 - accuracy: 0.8675\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 54s 7s/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f11e737bc40>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PIL\n",
    "print('Pillow Version:', PIL.__version__)\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from  matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "#generate dataset\n",
    "IMG_WIDTH=200\n",
    "IMG_HEIGHT=200\n",
    "img_path='train'\n",
    "#generate dataset\n",
    "IMG_WIDTH=200\n",
    "IMG_HEIGHT=200\n",
    "img_path='train1/'\n",
    "def generate_dataset(img_path):\n",
    "    img_data_array=[]\n",
    "    class_name=[]\n",
    "    for file in os.listdir(os.path.join(img_path)):\n",
    "        image = cv2.imread( img_path+file, cv2.COLOR_BGR2RGB)\n",
    "        try:\n",
    "            image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
    "        except:\n",
    "            break\n",
    "        image = np.array(image)\n",
    "        image = image.astype('float32')\n",
    "        image /= 255 \n",
    "        img_data_array.append(image)\n",
    "        # determine class\n",
    "        output = 0\n",
    "        if file.startswith('dog'):\n",
    "            output = 1\n",
    "        class_name.append(output)\n",
    "    return img_data_array, class_name\n",
    "# Get the image array and class name\n",
    "img_data, class_name = generate_dataset(img_path)\n",
    "\n",
    "'''Convert to array'''\n",
    "img_data=np.array(img_data)\n",
    "class_name=np.array(class_name)\n",
    "img_data.shape\n",
    "'''Dog mapping'''\n",
    "def dog_cat_mapping(a):\n",
    "    if a==\"dogs\":\n",
    "        return 1\n",
    "    else:return 0\n",
    "class_name=list(map(dog_cat_mapping,class_name))\n",
    "class_name=np.array(class_name)\n",
    "#input shape for model parameters\n",
    "input_shape=img_data.shape[1:]\n",
    "'''Modeling'''\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "conv_base=InceptionResNetV2(weights='imagenet',include_top=False,input_shape=(200,200,3))\n",
    "#Define the model\n",
    "def model():\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "    model=Sequential()\n",
    "    model.add(conv_base)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    return model\n",
    "model = model()\n",
    "#check structure\n",
    "#model.summary()\n",
    "conv_base.trainable = False\n",
    "#compile the model\n",
    "model.compile(optimizer = 'adam', \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "model.fit(x = img_data,y = class_name, epochs = 2)\n",
    "#save the model\n",
    "model.save('catdog.h5', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "model.save('catdog.h5', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.listdir(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "#image path\n",
    "img_path='train1/'\n",
    "photos = []\n",
    "labels = []\n",
    "from os import listdir\n",
    "for file in listdir(img_path):\n",
    "    # determine class\n",
    "    output = 0.0\n",
    "    if file.startswith('dog'):\n",
    "        output = 1.0\n",
    "    # load image\n",
    "    photo = load_img(img_path + file, target_size=(200, 200))\n",
    "    # convert to numpy array\n",
    "    photo = img_to_array(photo)\n",
    "    # store\n",
    "    photos.append(photo)\n",
    "    labels.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
